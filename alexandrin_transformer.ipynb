{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.tensorflow.org/tutorials/text/transformer\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "# Install TensorFlow\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import io\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import text from wiki\n",
    "with open('data/wiki-text.txt') as f:\n",
    "    data_wiki = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import text from dramacode\n",
    "with open('alexandrin.txt', encoding='utf-8') as f:\n",
    "    data_alex = f.read().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus of poetry length: 349904\n"
     ]
    }
   ],
   "source": [
    "corpus =  data_alex.lower().split(\"\\n\")#+data_wiki.lower().split(\"\\n\")\n",
    "#corpus = list(filter(lambda a: len(a) < 100, corpus))\n",
    "corpus = list(filter(lambda a: len(a) > 30, corpus))\n",
    "print('corpus of poetry length:', len(corpus))\n",
    "\n",
    "for line in corpus:\n",
    "    input_sequences.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total corpus length: 174952.0\n"
     ]
    }
   ],
   "source": [
    "# We want to predit the next sentence from a sentence \n",
    "n_seq = len(input_sequences)    \n",
    "output_sequences = input_sequences[1:n_seq:2]\n",
    "input_sequences = input_sequences[:n_seq-1:2]\n",
    "print(\"total corpus length:\", n_seq/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    tokenizer = tfds.features.text.SubwordTextEncoder.load_from_file('vocab_enconder')\n",
    "except:\n",
    "    tokenizer = tfds.features.text.SubwordTextEncoder.build_from_corpus(corpus, target_vocab_size=2**16)\n",
    "    tokenizer.save_to_file('vocab_enconder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((input_sequences,output_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer.vocab_size] + tokenizer.encode(\n",
    "        lang1.numpy()) + [tokenizer.vocab_size+1]\n",
    "    lang2 = [tokenizer.vocab_size] + tokenizer.encode(\n",
    "        lang2.numpy()) + [tokenizer.vocab_size+1]\n",
    "    return lang1, lang2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length, tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_encode(input_, output_):\n",
    "    return tf.py_function(encode, [input_, output_], [tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it.\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "num_layers = 6\n",
    "d_model = 512\n",
    "dff = 2048\n",
    "num_heads = 8\n",
    "\n",
    "input_vocab_size = tokenizer.vocab_size + 2\n",
    "target_vocab_size = tokenizer.vocab_size + 2\n",
    "dropout_rate = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "  \n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "  \n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "  \n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaled dot product attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(\n",
    "      q, k, v, None)\n",
    "    print ('Attention weights are:')\n",
    "    print (temp_attn)\n",
    "    print ('Output is:')\n",
    "    print (temp_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-head attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point wise feed forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(dff, activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(d_model)  # (batch_size, seq_len, d_model)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "          x = self.enc_layers[i](x, training, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "                 maximum_position_encoding, rate=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                           for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, \n",
    "            look_ahead_mask, padding_mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "          x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "          attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "          attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, \n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, \n",
    "                               input_vocab_size, pe_input, rate)\n",
    "\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, \n",
    "                               target_vocab_size, pe_target, rate)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "             look_ahead_mask, dec_padding_mask):\n",
    "\n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
    "    name='train_accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, \n",
    "                          pe_input=input_vocab_size, \n",
    "                          pe_target=target_vocab_size,\n",
    "                          rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                           optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    #ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print ('Latest checkpoint restored!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The @tf.function trace-compiles train_step into a TF graph for faster\n",
    "# execution. The function specializes to the precise shape of the argument\n",
    "# tensors. To avoid re-tracing due to the variable sequence lengths or variable\n",
    "# batch sizes (the last batch is smaller), use input_signature to specify\n",
    "# more generic shapes.\n",
    "\n",
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp, \n",
    "                                     True, \n",
    "                                     enc_padding_mask, \n",
    "                                     combined_mask, \n",
    "                                     dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "\n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "    start_token = [tokenizer.vocab_size]\n",
    "    end_token = [tokenizer.vocab_size + 1]\n",
    "\n",
    "    inp_sentence = start_token + tokenizer.encode(inp_sentence) + end_token\n",
    "    encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "\n",
    "    decoder_input = [tokenizer.vocab_size]\n",
    "    output = tf.expand_dims(decoder_input, 0)\n",
    "\n",
    "    for i in range(MAX_LENGTH):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "            encoder_input, output)\n",
    "\n",
    "        # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "        predictions, attention_weights = transformer(encoder_input, \n",
    "                                                     output,\n",
    "                                                     False,\n",
    "                                                     enc_padding_mask,\n",
    "                                                     combined_mask,\n",
    "                                                     dec_padding_mask)\n",
    "\n",
    "        # select the last word from the seq_len dimension\n",
    "        predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "        temperature = 1.0\n",
    "        predictions = predictions / temperature\n",
    "        #choose randomly a token from the k tokens of bigest probability\n",
    "        k=2\n",
    "        rand_id = np.argmax(np.random.rand(k))\n",
    "        predicted_ids = tf.math.top_k(predictions, k=k)[1]\n",
    "        predicted_id = tf.cast(predicted_ids[:,:,rand_id], tf.int32)\n",
    "\n",
    "        \n",
    "        # return the result if the predicted_id is equal to the end token\n",
    "        if predicted_id == tokenizer.vocab_size+1:\n",
    "            return tf.squeeze(output, axis=0), attention_weights\n",
    "\n",
    "        # concatentate the predicted_id to the output which is given to the decoder\n",
    "        # as its input.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "\n",
    "    sentence = tokenizer.encode(sentence)\n",
    "\n",
    "    attention = tf.squeeze(attention[layer], axis=0)\n",
    "\n",
    "    for head in range(attention.shape[0]):\n",
    "        ax = fig.add_subplot(2, 4, head+1)\n",
    "\n",
    "        # plot the attention weights\n",
    "        ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "        fontdict = {'fontsize': 10}\n",
    "\n",
    "        ax.set_xticks(range(len(sentence)+2))\n",
    "        ax.set_yticks(range(len(result)))\n",
    "\n",
    "        ax.set_ylim(len(result)-1.5, -0.5)\n",
    "\n",
    "        ax.set_xticklabels(\n",
    "            ['<start>']+[tokenizer.decode([i]) for i in sentence]+['<end>'], \n",
    "            fontdict=fontdict, rotation=90)\n",
    "\n",
    "        ax.set_yticklabels([tokenizer.decode([i]) for i in result \n",
    "                            if i < tokenizer.vocab_size], \n",
    "                           fontdict=fontdict)\n",
    "\n",
    "        ax.set_xlabel('Head {}'.format(head+1))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_verse(sentence, plot=''):\n",
    "    result, attention_weights = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer.decode([i for i in result \n",
    "                                            if i < tokenizer.vocab_size])  \n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted next verse: {}'.format(predicted_sentence))\n",
    "\n",
    "    if plot:\n",
    "        plot_attention_weights(attention_weights, sentence, result, plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_poeme(src = \"\", n_verses = 4):\n",
    "    if src == \"\":\n",
    "        src = input_sequences[np.random.randint(n_seq/2)]\n",
    "    for i in range(n_verses):\n",
    "        result, attention_weights = evaluate(src)\n",
    "\n",
    "        predicted_sentence = tokenizer.decode([i for i in result \n",
    "                                            if i < tokenizer.vocab_size])  \n",
    "        src = predicted_sentence\n",
    "        print(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 1.6434 Accuracy 0.0695\n",
      "Epoch 1 Batch 500 Loss 1.5436 Accuracy 0.0639\n",
      "Epoch 1 Batch 1000 Loss 1.8639 Accuracy 0.0748\n",
      "Epoch 1 Batch 1500 Loss 2.1170 Accuracy 0.0888\n",
      "Epoch 1 Batch 2000 Loss 2.2788 Accuracy 0.1001\n",
      "Epoch 1 Batch 2500 Loss 2.3980 Accuracy 0.1076\n",
      "Epoch 1 Loss 2.4375 Accuracy 0.1105\n",
      "Time taken for 1 epoch: 1486.91370844841 secs\n",
      "\n",
      "Sample of generation :\n",
      "\n",
      "je sais de son amour est un peu de ma mort.          -même,  ..  -\n",
      "et je n'y ai pas qu, il faut que le plus de son père.  -même crime.  .-là  \n",
      "je ne sais rien de la gloire.  .\n",
      "que le sort est toujours de son tour ;  .\n",
      "Epoch 2 Batch 0 Loss 0.8458 Accuracy 0.0415\n",
      "Epoch 2 Batch 500 Loss 1.4750 Accuracy 0.0653\n",
      "Epoch 2 Batch 1000 Loss 1.7935 Accuracy 0.0765\n",
      "Epoch 2 Batch 1500 Loss 2.0520 Accuracy 0.0906\n",
      "Epoch 2 Batch 2000 Loss 2.2158 Accuracy 0.1021\n",
      "Epoch 2 Batch 2500 Loss 2.3381 Accuracy 0.1099\n",
      "Epoch 2 Loss 2.3826 Accuracy 0.1128\n",
      "Time taken for 1 epoch: 1491.5796031951904 secs\n",
      "\n",
      "Sample of generation :\n",
      "\n",
      "mais qu'à vous voir la vertu d-on fait,  \n",
      "je veux voir de mes voeux de mes jours,  -à ?  -même.  .  -être  -il que vous l’on faire  -on vous plaindre,  \n",
      "mais si je dois bien voir qu. on m, à l. il vous l. en a fait ;    \n",
      "je n’y veux un peu d, une belle affaire ;  .  ..  -je le dire.  \n",
      "Epoch 3 Batch 0 Loss 1.5344 Accuracy 0.0587\n",
      "Epoch 3 Batch 500 Loss 1.4860 Accuracy 0.0675\n",
      "Epoch 3 Batch 1000 Loss 1.7540 Accuracy 0.0773\n",
      "Epoch 3 Batch 1500 Loss 2.0037 Accuracy 0.0912\n",
      "Epoch 3 Batch 2000 Loss 2.1707 Accuracy 0.1029\n",
      "Epoch 3 Batch 2500 Loss 2.2955 Accuracy 0.1110\n",
      "Epoch 3 Loss 2.3383 Accuracy 0.1140\n",
      "Time taken for 1 epoch: 1488.8625028133392 secs\n",
      "\n",
      "Sample of generation :\n",
      "\n",
      "mais si je n. un roi d. il vous a su entendre.  \n",
      "je veux qu’il ne soit pas de ce qu, une reine :  .-il m,  .-on vous donne.    ..\n",
      "il a de la main de vous mettre de moi ;  ..  \n",
      "et pour avoir fait voir que j’avais de mon âme ?  ..\n",
      "Epoch 4 Batch 0 Loss 0.9587 Accuracy 0.0481\n",
      "Epoch 4 Batch 500 Loss 1.4510 Accuracy 0.0680\n",
      "Epoch 4 Batch 1000 Loss 1.7019 Accuracy 0.0776\n",
      "Epoch 4 Batch 1500 Loss 1.9650 Accuracy 0.0921\n",
      "Epoch 4 Batch 2000 Loss 2.1348 Accuracy 0.1037\n",
      "Epoch 4 Batch 2500 Loss 2.2615 Accuracy 0.1120\n",
      "Epoch 4 Loss 2.3046 Accuracy 0.1150\n",
      "Time taken for 1 epoch: 1547.079889535904 secs\n",
      "\n",
      "Sample of generation :\n",
      "\n",
      "je n-tu pas qu'elle est vrai qui m, on me soit à sa vie,  s  ..-.  .  ..  .s’est chère ?  .\n",
      "mais si je veux que l, un roi si beau si funeste  -.  s,  s'\n",
      "mais si tu suis de vous servir le coeur ;  .  .  .      \n",
      "que l, il se a vu ce qu, elle aime, mais il a la gloire.  \n",
      "Epoch 5 Batch 0 Loss 1.7414 Accuracy 0.0974\n",
      "Epoch 5 Batch 500 Loss 1.4151 Accuracy 0.0684\n",
      "Epoch 5 Batch 1000 Loss 1.7000 Accuracy 0.0789\n",
      "Epoch 5 Batch 1500 Loss 1.9561 Accuracy 0.0937\n",
      "Epoch 5 Batch 2000 Loss 2.1221 Accuracy 0.1054\n",
      "Epoch 5 Batch 2500 Loss 2.2426 Accuracy 0.1132\n",
      "Saving checkpoint for epoch 5 at ./checkpoints/train\\ckpt-1\n",
      "Epoch 5 Loss 2.2883 Accuracy 0.1164\n",
      "Time taken for 1 epoch: 1693.3086879253387 secs\n",
      "\n",
      "Sample of generation :\n",
      "\n",
      "je ne veux point d, à son sang d. un autre roi  \n",
      "que je dois à son amour une autre flamme ?  ,    \n",
      "que la fortune à son ambition.  \n",
      "je ne puis que je dois le sais.  \n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "\n",
    "        if batch % 500 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "              epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
    "                                                             ckpt_save_path))\n",
    "\n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1, \n",
    "                                                train_loss.result(), \n",
    "                                                train_accuracy.result()))\n",
    "\n",
    "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n",
    "    \n",
    "    print ('Sample of generation :\\n')\n",
    "    generate_poeme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Vers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mais je ne puis pas que de l’on ne a pas de craindre,  \n",
      "que le sort est grand que le plus beau des plus doux,  \n",
      "et que le ciel est un bien grand avantage,  .\n",
      "        mais je veux bien à mon père,  \n",
      "et que je ne veux point de ce que j’ay fait naître  \n",
      "mais que le ciel est un bien grand avantage,  \n",
      "que le sort de mon coeur ne se peut pas plus d,  -être à vous.  \n",
      "que je ne veux pas de mon coeur que je me dois voir,  .\n",
      "mais je ne puis point que de ce que j’ay fait naître,  ..\n",
      "que le sort de mon sang ne peut pas rien d’un crime.  \n"
     ]
    }
   ],
   "source": [
    "generate_poeme(src = \"Tout bourgeois veut bâtir comme les grands seigneurs\", n_verses=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mais je ne puis point que de ce n. il faut que je suis.  \n",
      "                                                , et je ne sais rien,  -être pas,  \n",
      "que je ne puis point de ce qu. on a fait faire.  -même.  \n",
      "mais que le sort est un bien de la gloire,  \n",
      "et je ne sais pas pas que des plus grands  ....\n",
      "mais que je veux à vos yeux ce que je dois faire  .\n",
      "mais que je veux à mon sang une telle victoire,  \n",
      "et je veux que mon bras ne fut point de moi.  .\n",
      "                mais que je suis le prix des rois,  \n",
      "que je suis le moins que je vous dois voir.  -être en effet.  .\n"
     ]
    }
   ],
   "source": [
    "generate_poeme(src = \"\", n_verses=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
